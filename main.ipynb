{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm4ApUtmLrHT"
      },
      "source": [
        "## COMP 579 Final Project\n",
        "- Ronald\n",
        "- Sienna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCJy_Waqs-yi"
      },
      "source": [
        "### cpu / gpu count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flGhnER4s98M",
        "outputId": "352a06cc-5cdd-4033-fa59-1ee05da47c1f"
      },
      "outputs": [],
      "source": [
        "# CPU cores\n",
        "import multiprocessing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "print(\"Number of CPU cores: \",num_cores)\n",
        "\n",
        "# CUDA cores\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  print(\"CUDA is not available.\")\n",
        "else:\n",
        "  device = torch.cuda.current_device()\n",
        "  properties = torch.cuda.get_device_properties(device)\n",
        "  cores = properties.multi_processor_count\n",
        "  print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "  print(f\"Number of CUDA cores: {cores}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi_f2ZZdvHqx"
      },
      "source": [
        "### install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MhOAnglTMIKt",
        "outputId": "dae0fe25-9cae-44d2-e918-ad4bb0a29707"
      },
      "outputs": [],
      "source": [
        "# !pip install pettingzoo\n",
        "# !pip install shimmy[openspiel]\n",
        "\n",
        "# !pip install torchrl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LgSdfhDLrHV"
      },
      "source": [
        "### project directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI5wPs-SLrHV",
        "outputId": "2b3bd303-d6ba-4e3c-a4b0-61ced4d5117a"
      },
      "outputs": [],
      "source": [
        "# Setting up project working directory\n",
        "import os\n",
        "# Changing project directory if working on remote machine\n",
        "# PROJECT_DIRECTORY = \"/home/ronald/579/final-project\"\n",
        "# os.chdir(PROJECT_DIRECTORY)\n",
        "print(f\"current working directory: {os.getcwd()}\")\n",
        "# ensure that the project directory is in the search path (for modules)\n",
        "import sys\n",
        "sys.path.append(os.getcwd())\n",
        "print(f\"added search path: {os.getcwd()}\")\n",
        "\n",
        "# Setting default directory for saving/loading data\n",
        "DIRECTORY_NAME = \"comp-579-final-project-data\"\n",
        "if not os.path.exists(DIRECTORY_NAME):\n",
        "    os.makedirs(DIRECTORY_NAME)\n",
        "    DIRECTORY_PATH = os.path.abspath(DIRECTORY_NAME)\n",
        "else:\n",
        "    DIRECTORY_PATH = os.path.abspath(DIRECTORY_NAME)\n",
        "print(f\"save/load data directory: {DIRECTORY_PATH}\")\n",
        "\n",
        "# This should be internal to run.py once run.load(data_id) is implemented\n",
        "# Helper functions to save/load training data\n",
        "import pickle\n",
        "def save(object, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(object, f)\n",
        "def load(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        object = pickle.load(f)\n",
        "    return object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agq8lXMrsaw9"
      },
      "source": [
        "### import classes and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jY0DJD2L8nM"
      },
      "outputs": [],
      "source": [
        "from pettingzoo.classic.hanabi import hanabi\n",
        "import torch.optim as optim\n",
        "\n",
        "from network_models import DQN\n",
        "from memory_models import ReplayMemory, PrioritizedReplayMemory\n",
        "from agents import HumanAgent, RandomAgent, DQNAgent, DDQNAgent\n",
        "import training_online as online\n",
        "import training_offline as offline\n",
        "import testing as test\n",
        "\n",
        "# ignoring deprecation warnings\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0cqShTmLrHY"
      },
      "source": [
        "### plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akiQZu3BLrHY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# set up matplotlib\n",
        "# is_ipython = 'inline' in matplotlib.get_backend()\n",
        "# if is_ipython:\n",
        "#     from IPython import display\n",
        "# plt.ion()\n",
        "\n",
        "def plot_trial(trial_output):\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "\n",
        "    ax.plot(trial_output)\n",
        "\n",
        "    ax.set_xlabel(\"Episode\", fontsize=14)\n",
        "    ax.set_ylabel(\"Score\", fontsize=14)\n",
        "    ax.set_title(f\"Score over 1 Trial\", fontsize=16)\n",
        "    # Set the major tick locators for y-axis to display only integers\n",
        "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_trials(trials_output, curve_label='', data_id=None):\n",
        "    trials_output = np.array(trials_output)\n",
        "    num_trials = len(trials_output)\n",
        "\n",
        "    # Compute statistics across trials\n",
        "    mean_rewards = np.mean(trials_output, axis=0)\n",
        "    std_rewards = np.std(trials_output, axis=0)\n",
        "\n",
        "    # Plot mean rewards with shading for standard deviation\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "    plt.plot(mean_rewards, label='')\n",
        "    plt.fill_between(range(len(mean_rewards)), mean_rewards - std_rewards, mean_rewards + std_rewards, color='lightblue', alpha=0.3)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel(f'Average Score over {num_trials} Trials')\n",
        "    plt.title(curve_label)\n",
        "    plt.legend()\n",
        "    #plt.grid(True)\n",
        "    if data_id is not None:\n",
        "        plt.savefig(os.path.join(DIRECTORY_PATH, f'{data_id}.png'))\n",
        "    plt.show()\n",
        "\n",
        "def plot_trialss(trials_outputs, curve_labels):\n",
        "    \"\"\"\n",
        "    Preconditions:\n",
        "        - len(trials_outputs) == len(curve_labels)\n",
        "    Parameters:\n",
        "        trials_outputs: list of lists of floats\n",
        "        curve_labels: list of strings\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "    for trials_output, curve_label in zip(trials_outputs, curve_labels):\n",
        "        trials_output = np.array(trials_output)\n",
        "        num_trials = len(trials_output)\n",
        "\n",
        "        # Compute statistics across trials\n",
        "        mean_rewards = np.mean(trials_output, axis=0)\n",
        "        std_rewards = np.std(trials_output, axis=0)\n",
        "\n",
        "        # Plot mean rewards with shading for standard deviation\n",
        "        plt.plot(mean_rewards, label=curve_label)\n",
        "        plt.fill_between(range(len(mean_rewards)), mean_rewards - std_rewards, mean_rewards + std_rewards, alpha=0.3)\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title(f'Performance of Different Agents')\n",
        "    plt.legend()\n",
        "    #plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_agents(trials_output_dict, curve_label_dict):\n",
        "    \"\"\"\n",
        "    Preconditions:\n",
        "        - len(trials_output_dict) == len(curve_label_dict)\n",
        "    Parameters:\n",
        "        trials_output_dict: dictionary of lists of floats\n",
        "        curve_label_dict: dictionary of strings\n",
        "    \"\"\"\n",
        "    trials_outputs = trials_output_dict.values()\n",
        "    curve_labels = curve_label_dict.values()\n",
        "    plot_trialss(trials_outputs, curve_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqhVNxY5HYgo"
      },
      "source": [
        "## DQN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to record execution time\n",
        "import time\n",
        "\n",
        "# Storing training results for plotting\n",
        "trials_output = {}\n",
        "curve_label = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "env_constructor = hanabi.env\n",
        "env = env_constructor(render_mode=\"human\", players=2)\n",
        "env.reset()\n",
        "\n",
        "N_ACTIONS = env.action_space('player_0').n # assuming same number of actions for all players\n",
        "N_OBSERVATIONS = env.observation_vector_dim[0]\n",
        "\n",
        "# Agent settings\n",
        "HIDDEN_LAYERS = [512,512] # HIDDEN_LAYERS is the list of number of neurons for each hidden layer\n",
        "policy_net = DQN(N_OBSERVATIONS, N_ACTIONS, HIDDEN_LAYERS)\n",
        "target_net = DQN(N_OBSERVATIONS, N_ACTIONS, HIDDEN_LAYERS)\n",
        "LR = 1e-4 # LR is the learning rate of the ``AdamW`` optimizer\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR)\n",
        "memory = ReplayMemory(10000) # MEMORY_SIZE is the size of replay buffer\n",
        "BATCH_SIZE = 256 # BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "GAMMA = 1\n",
        "TAU = 0.005\n",
        "EPS_START = 1\n",
        "EPS_END = 0\n",
        "EPS_DECAY = 10000 # decay \"temperature\"\n",
        "\n",
        "agent1 = DQNAgent(policy_net, target_net, optimizer, memory, BATCH_SIZE, GAMMA, TAU, EPS_START, EPS_END, EPS_DECAY)\n",
        "agent2 = DQNAgent(policy_net, target_net, optimizer, memory, BATCH_SIZE, GAMMA, TAU, EPS_START, EPS_END, EPS_DECAY)\n",
        "agents = [agent1, agent2]\n",
        "\n",
        "# trial setting\n",
        "N_EPISODES = 5000\n",
        "N_TRIALS = 1\n",
        "RETURNS_OUTPUT_EPISODES = [1, 9999, 19999, 29999, 39999, 49999, 59999, 69999, 79999, 89999, N_EPISODES - 1] # manually select episodes to save returns\n",
        "AGENTS_OUTPUT_EPISODES = [1, 9999, 19999, 29999, 39999, 49999, 59999, 69999, 79999, 89999, N_EPISODES - 1] # manually select episodes to save agents\n",
        "DATA_ID = f\"{N_TRIALS}-trials-{int(N_EPISODES/1000)}k__DQN\" # id used for save/load filename\n",
        "\n",
        "\n",
        "# CHOOSE WHAT TO RUN\n",
        "\n",
        "start_time = time.time()\n",
        "# run_episode(env, [agent1, agent2], \"human\")\n",
        "# trial_output = offline.run_trial(env_constructor, agents, N_EPISODES, [], RETURNS_OUTPUT_EPISODES, AGENTS_OUTPUT_EPISODES, DIRECTORY_PATH, DATA_ID)\n",
        "# trials_output[DATA_ID] = offline.run_trials_sequential(env_constructor, agents, N_TRIALS, N_EPISODES, RETURNS_OUTPUT_EPISODES, AGENTS_OUTPUT_EPISODES, DIRECTORY_PATH, DATA_ID, verbose=True)\n",
        "trials_output[DATA_ID] = offline.run_trials_parallel(env_constructor, agents, N_TRIALS, N_EPISODES, RETURNS_OUTPUT_EPISODES, AGENTS_OUTPUT_EPISODES, DIRECTORY_PATH, DATA_ID, verbose=True)\n",
        "end_time = time.time()\n",
        "\n",
        "with open(f\"{DIRECTORY_PATH}/{DATA_ID}__ep{N_EPISODES-1}.txt\", \"w\") as f:\n",
        "     print(f\"Execution time: {end_time - start_time} seconds\", file=f)\n",
        "\n",
        "# Plotting\n",
        "curve_label[DATA_ID] = DATA_ID\n",
        "# concatenate data_id with number of episodes\n",
        "filename__plot = f\"{DATA_ID}__ep{N_EPISODES-1}\"\n",
        "plot_trials(trials_output[DATA_ID], curve_label[DATA_ID], filename__plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def DQN_load_agents(filename_player0, filename_player1):\n",
        "    agent0 = DQNAgent.load(filename_player0)\n",
        "    agent1 = DQNAgent.load(filename_player1)\n",
        "    agent1.policy_net = agent0.policy_net\n",
        "    agent1.target_net = agent0.target_net\n",
        "    agent1.memory = agent0.memory\n",
        "    return [agent0, agent1]\n",
        "# def DDQN_load_agents...\n",
        "# def PDDQN_load_agents...\n",
        "# To do: generalize interface for loading any agents\n",
        "# To do: training_offline.continue_run_trials_parallel(...)\n",
        "\n",
        "filename_player0 = os.path.join(DIRECTORY_PATH, \"8-trials-100k__DQN__1e-4__M10000__B256/DQN__1e-4__M10000B256__trial5__ep99999__player0.pt\")\n",
        "filename_player1 = os.path.join(DIRECTORY_PATH, \"8-trials-100k__DQN__1e-4__M10000__B256/DQN__1e-4__M10000B256__trial5__ep99999__player0.pt\")\n",
        "loaded_agents = DQN_load_agents(filename_player0, filename_player1)\n",
        "# agents = [RandomAgent(), RandomAgent()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Loaded Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Agent 0 steps done: \", loaded_agents[0].steps_done)\n",
        "print(\"Agent 1 steps done: \", loaded_agents[1].steps_done)\n",
        "# print(\"Agent 0 policy_net:\\n\", agents[0].policy_net.state_dict())\n",
        "# print(\"*******************************************************************\")\n",
        "# print(\"Agent 1 policy_net:\\n\", agents[1].policy_net.state_dict())\n",
        "\n",
        "env_constructor = hanabi.env\n",
        "env = env_constructor(render_mode=\"human\", players=2)\n",
        "env.reset()\n",
        "\n",
        "# trial setting\n",
        "N_EPISODES = 100\n",
        "N_TRIALS = 1\n",
        "RETURNS_OUTPUT_EPISODES = [] # manually select episodes to save returns\n",
        "AGENTS_OUTPUT_EPISODES = [] # manually select episodes to save agents\n",
        "DATA_ID = None # id used for save/load filename\n",
        "\n",
        "# run testing\n",
        "trial_output = test.run_trial(env_constructor, loaded_agents, N_EPISODES, [], RETURNS_OUTPUT_EPISODES, AGENTS_OUTPUT_EPISODES, DIRECTORY_PATH, DATA_ID, False)\n",
        "\n",
        "# mean score\n",
        "print(\"Mean score: \", np.mean(trial_output))\n",
        "\n",
        "# Plotting\n",
        "# plot_trial(trial_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc_RXbP63AQy"
      },
      "source": [
        "## Comparing all Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "aoRnRMSp3GnC",
        "outputId": "eac1f896-7d16-45ba-a953-4d829dbe8562"
      },
      "outputs": [],
      "source": [
        "# plot_agents(trials_output, curve_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Continue Training with DQN Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def DQN_load_agents(filename_player0, filename_player1):\n",
        "#     agent0 = DQNAgent.load(filename_player0)\n",
        "#     agent0 = DQNAgent.load(filename_player1)\n",
        "#     agent1.policy_net = agent0.policy_net\n",
        "#     agent1.target_net = agent0.target_net\n",
        "#     return [agent0, agent1]\n",
        "# def DDQN_load_agents...\n",
        "# def PDDQN_load_agents...\n",
        "# To do: generalize interface for loading any agents\n",
        "# To do: training_offline.continue_run_trials_parallel(...)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trial_loaded = load(os.path.join(DIRECTORY_PATH, f\"DQN__LZY__2x512__1e-4__M10000B256__trial5__ep70000__trial_output.pkl\"))\n",
        "# curve_label_loaded = 'DQN__LZY__2x512__1e-4__M10000B256'\n",
        "# plot_trial(trial_loaded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trials_loaded = []\n",
        "# for trial in range(8):\n",
        "#     trials_loaded.append(load(os.path.join(DIRECTORY_PATH, f\"DQN__LZY__2x512__1e-4__M10000B256__trial{trial}__ep70000__trial_output.pkl\")))\n",
        "# curve_label_loaded = ['DQN Lazy 1e-4 M10000B256']\n",
        "# plot_trials(trials_loaded, curve_label_loaded)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
